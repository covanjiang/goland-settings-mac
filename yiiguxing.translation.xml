<application>
  <component name="AppStorage">
    <option name="newTranslationDialogHeight" value="613" />
    <option name="newTranslationDialogWidth" value="1050" />
    <option name="newTranslationDialogX" value="267" />
    <option name="newTranslationDialogY" value="218" />
    <histories>
      <item value="Select" />
      <item value="The error built-in interface type is the conventional interface for&#10; representing an error condition, with the nil value representing no error." />
      <item value="Indicator" />
      <item value="We don't want the entry's metadata to be quoted and escaped (if it's&#10;&#9; encoded as strings), which means that we can't use the JSON encoder. The&#10;&#9; simplest option is to use the memory encoder and fmt.Fprint.&#10;&#9;&#10;&#9; If this ever becomes a performance bottleneck, we can implement&#10;&#9; ArrayEncoder for our plain-text format." />
      <item value="Configure the primitive representations of common complex types. For&#10;&#9; example, some users may want all time.Times serialized as floating-point&#10;&#9; seconds since epoch, while others may prefer ISO8601 strings." />
      <item value="defines the key to use when callers want to remove a key from log output." />
      <item value="relative path" />
      <item value="et rotate daily (chainable). Must be called before the first log message is" />
      <item value="Set file log saving hours, if file is expired, will be deleted now." />
      <item value="Word Date" />
      <item value="Indent appends to dst an indented form of the JSON-encoded src. Each element in a JSON object or array begins on a new, indented line beginning with prefix followed by one or more copies of indent according to the indentation nesting. The data appended to dst does not begin with the prefix nor any indentation, to make it easier to embed inside other formatted JSON data. Although leading space characters (space, tab, carriage return, newline) at the beginning of src are dropped, trailing space characters at the end of src are preserved and copied to dst. For example, if src has no trailing spaces, neither will dst; if src ends in a trailing newline, so will dst." />
      <item value="external action" />
      <item value="defines the functions clients need to perform unary and&#10; streaming RPCs.  It is implemented by ClientConn, and is only intended to&#10; be referenced by generated code." />
      <item value="ddFunc adds a func to the Cron to be run on the given schedule.&#10; The spec is parsed using the time zone of this Cron instance as the default.&#10; An opaque ID is returned that can be used to later remove it." />
      <item value="Campaign" />
      <item value="must start a consumer loop of ConsumerGroupClaim's Messages()." />
      <item value="For each of the assigned claims the handler's ConsumeClaim() function is then called&#10;&#9;    in a separate goroutine which requires it to be thread-safe. Any state must be carefully protected" />
      <item value="Please note, that once a rebalance is triggered, sessions must be completed within&#10;&#9; Config.Consumer.Group.Rebalance.Timeout. This means that ConsumeClaim() functions must exit&#10;&#9; as quickly as possible to allow time for Cleanup() and the final offset commit. If the timeout&#10;&#9; is exceeded, the consumer will be removed from the group by Kafka, which will cause offset&#10;&#9; commit failures." />
      <item value="Once all the ConsumeClaim() loops have exited, the handler's Cleanup() hook is called&#10;&#9;    to allow the user to perform any final tasks before a rebalance." />
      <item value="The session will persist until one of the ConsumeClaim() functions exits. This can be either when the&#10;&#9;    parent context is cancelled or when a server-side rebalance cycle is initiated." />
      <item value="For each of the assigned claims the handler's ConsumeClaim() function is then called&#10;&#9;    in a separate goroutine which requires it to be thread-safe. Any state must be carefully protected&#10;&#9;    from concurrent readswrites." />
      <item value="must start a consumer loop of ConsumerGroupClaim's Messages().&#10;&#9; Once the Messages() channel is closed, the Handler must finish its processing&#10;&#9; loop and exit." />
      <item value=" Consume joins a cluster of consumers for a given list of topics and&#10;&#9; starts a blocking ConsumerGroupSession through the ConsumerGroupHandler.&#10;&#9;&#10;&#9; The life-cycle of a session is represented by the following steps:&#10;&#9;&#10;&#9; 1. The consumers join the group (as explained in https:kafka.apache.orgdocumentationintro_consumers)&#10;&#9;    and is assigned their &quot;fair share&quot; of partitions, aka 'claims'.&#10;&#9; 2. Before processing starts, the handler's Setup() hook is called to notify the user&#10;&#9;    of the claims and allow any necessary preparation or alteration of state.&#10;&#9; 3. For each of the assigned claims the handler's ConsumeClaim() function is then called&#10;&#9;    in a separate goroutine which requires it to be thread-safe. Any state must be carefully protected&#10;&#9;    from concurrent readswrites.&#10;&#9; 4. The session will persist until one of the ConsumeClaim() functions exits. This can be either when the&#10;&#9;    parent context is cancelled or when a server-side rebalance cycle is initiated.&#10;&#9; 5. Once all the ConsumeClaim() loops have exited, the handler's Cleanup() hook is called&#10;&#9;    to allow the user to perform any final tasks before a rebalance.&#10;&#9; 6. Finally, marked offsets are committed one last time before claims are released.&#10;&#9;&#10;&#9; Please note, that once a rebalance is triggered, sessions must be completed within&#10;&#9; Config.Consumer.Group.Rebalance.Timeout. This means that ConsumeClaim() functions must exit&#10;&#9; as quickly as possible to allow time for Cleanup() and the final offset commit. If the timeout&#10;&#9; is exceeded, the consumer will be removed from the group by Kafka, which will cause offset&#10;&#9; commit failures.&#10;&#9; This method should be called inside an infinite loop, when a&#10;&#9; server-side rebalance happens, the consumer session will need to be&#10;&#9; recreated to get the new claims." />
      <item value="`Consume` should be called inside an infinite loop, when a&#10;&#9;&#9;&#9; server-side rebalance happens, the consumer session will need to be&#10;&#9;&#9;&#9; recreated to get the new claims" />
      <item value="Background returns a non-nil, empty Context. It is never canceled, has no&#10; values, and has no deadline. It is typically used by the main function,&#10; initialization, and tests, and as the top-level Context for incoming&#10; requests." />
      <item value="WithCancel returns a copy of parent with a new Done channel. The returned&#10; context's Done channel is closed when the returned cancel function is called&#10; or when the parent context's Done channel is closed, whichever happens first.&#10;&#10; Canceling this context releases resources associated with it, so code should&#10; call cancel as soon as the operations running in this Context complete." />
      <item value="returns a copy of parent with a new Done channel. The returned&#10; context's Done channel is closed when the returned cancel function is called&#10; or when the parent context's Done channel is closed, whichever happens first.&#10;&#10; Canceling this context releases resources associated with it, so code should&#10; call cancel as soon as the operations running in this Context complete." />
      <item value="Getwd returns a rooted path name corresponding to the&#10; current directory. If the current directory can be&#10; reached via multiple paths (due to symbolic links),&#10; Getwd may return any one of them." />
      <item value="Getwd returns a rooted path name corresponding to the current directory. If the current directory can be reached via multiple paths (due to symbolic links), Getwd may return any one of them." />
      <item value="returns the reverse order for data." />
      <item value="Pop removes and returns the minimum element (according to Less) from the heap.&#10; The complexity is O(log n) where n = h.Len().&#10; Pop is equivalent to Remove(h, 0)." />
      <item value="SearchInts searches for x in a sorted slice of ints and returns the index&#10; as specified by Search. The return value is the index to insert x if x is&#10; not present (it could be len(a)).&#10; The slice must be sorted in ascending order." />
      <item value="Fix re-establishes the heap ordering after the element at index i has changed its value.&#10; Changing the value of the element at index i and then calling Fix is equivalent to,&#10; but less expensive than, calling Remove(h, i) followed by a Push of the new value.&#10; The complexity is O(log n) where n = h.Len()." />
      <item value="IntSlice attaches the methods of Interface to []int, sorting in increasing order." />
      <item value="Scan scans text read from standard input, storing successive&#10; space-separated values into successive arguments. Newlines count&#10; as space. It returns the number of items successfully scanned.&#10; If that is less than the number of arguments, err will report why." />
      <item value="is a variable-sized buffer of bytes with Read and Write methods.&#10; The zero value for Buffer is an empty buffer ready to use." />
      <item value="Marshal traverses the value v recursively.&#10; If an encountered value implements the Marshaler interface&#10; and is not a nil pointer, Marshal calls its MarshalJSON method&#10; to produce JSON. If no MarshalJSON method is present but the&#10; value implements encoding.TextMarshaler instead, Marshal calls&#10; its MarshalText method and encodes the result as a JSON string.&#10; The nil pointer exception is not strictly necessary&#10; but mimics a similar, necessary exception in the behavior of&#10; UnmarshalJSON." />
      <item value=" Marshal returns the JSON encoding of v.&#10;" />
      <item value="adds the elements of the argument map to the template's function map.&#10; It panics if a value in the map is not a function with appropriate return&#10; type. However, it is legal to overwrite elements of the map. The return&#10; value is the template, so calls can be chained." />
      <item value="FuncMap is the type of the map defining the mapping from names to functions.&#10; Each function must have either a single return value, or two return values of&#10; which the second has type error. In that case, if the second (error)&#10; return value evaluates to non-nil during execution, execution terminates and&#10; Execute returns that error." />
      <item value="checks the Content-Type to select a binding engine automatically,&#10; Depending the &quot;Content-Type&quot; header different bindings are used:&#10;     &quot;applicationjson&quot; --&gt; JSON binding&#10;     &quot;applicationxml&quot;  --&gt; XML binding&#10; otherwise --&gt; returns an error&#10; It parses the request's body as JSON if Content-Type == &quot;applicationjson&quot; using JSON or XML as a JSON input.&#10; It decodes the json payload into the struct specified as a pointer.&#10; Like c.Bind() but this method does not set the response status code to 400 and abort if the json is not valid." />
      <item value=" set log mode, `true` for detailed logs, `false` for no log, default, will only print error logs" />
      <item value="use singular table by default" />
      <item value="takes a single key and unmarshals it into a Struct." />
      <item value="Viper is a prioritized configuration registry. It&#10; maintains a set of configuration sources, fetches&#10; values to populate those, and provides them according&#10; to the source's priority." />
      <item value="itle returns a copy of the string s with all Unicode letters that begin words&#10; mapped to their Unicode title case." />
      <item value="Replace returns a copy of the string s with the first n non-overlapping instances of old replaced by new. If old is empty, it matches at the beginning of the string and after each UTF-8 sequence, yielding up to k+1 replacements for a k-rune string. If n &lt; 0, there is no limit on the number of replacements.&#10;" />
      <item value="Parse parses flag definitions from the argument list, which should not&#10; include the command name. Must be called after all flags in the FlagSet&#10; are defined and before flags are accessed by the program.&#10; The return value will be ErrHelp if -help or -h were set but not defined." />
      <item value="NewFlagSet returns a new, empty flag set with the specified name and&#10; error handling property. If the name is not empty, it will be printed&#10; in the default usage message and in error messages." />
      <item value="These routines do not take a format string" />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="39" />
        <entry key="ENGLISH" value="40" />
      </map>
    </option>
  </component>
  <component name="Cache">
    <option name="lastTrimTime" value="1660885910455" />
  </component>
  <component name="Settings">
    <option name="keepFormat" value="true" />
  </component>
  <component name="Translation.Cache">
    <option name="lastTrimTime" value="1752117342449" />
  </component>
  <component name="Translation.Settings">
    <option name="primaryLanguage" value="CHINESE" />
    <option name="ttsEngine" value="GOOGLE" />
  </component>
  <component name="Translation.States">
    <histories>
      <item value="encountered" />
      <item value="third" />
      <item value="Ifnull(Round(Sum Ifnull(Round(Sum" />
      <item value="Deprecated" />
      <item value="GENCY" />
      <item value="Set sets the header entries associated with key to the single element value. It replaces any existing values associated with key. The key is case insensitive; it is canonicalized by [textproto.CanonicalMIMEHeaderKey]. To use non-canonical keys, assign to the map directly." />
      <item value="IdleConnTimeout is the maximum amount of time an idle (keep-alive) connection will remain idle before closing itself. Zero means no limit." />
      <item value="MaxIdleConnsPerHost, if non-zero, controls the maximum idle (keep-alive) connections to keep per-host. If zero, DefaultMaxIdleConnsPerHost is used." />
      <item value="Len returns the number of bytes of the unread portion of the buffer;" />
      <item value="EE t.dt As dt ,t.hr As HouK,t.uld.As account_10,t.exchange_10 As exchange_1d,cam.dsp_campalgn_10 AJ dSp_campa1gn_10， SUM（t.settled_ad_price） AS income,SUM（t.media_price）AS Cost,SUM（t.imp）AS imp， SUM（ t.CLk ）AS CLK, SUM（ t.act ）AS act,SUM（payment） FROM rtb_stats_hourly_view t LEFT JOIN rtb_campaign cam ON_cam.id = t.pid WHERE t.dt = 20240924 AND t.uid= 106273 GROUP BY t.dt,t.hr,t.uid,t.exchange_id；" />
      <item value="convertNumber converts the number literal s to a float64 or a Number depending on the setting of d.useNumber." />
      <item value="Don't save err from unmarshal into dec.err: the connection is still usable since we read a complete JSON object from it before the error happened." />
      <item value="UseNumber causes the Decoder to unmarshal a number into an interface{} as a [Number] instead of as a float64." />
      <item value="SkipPortValidation allows skipping the port validation in `ValidateConnection` This is useful when connecting to a MySQL instance where the external port may not match the internal port." />
      <item value="AliyunRDS set users port to &quot;NULL&quot;, replace it by gh-ost param GCP set users port to &quot;NULL&quot;, replace it by gh-ost param Azure MySQL set users port to a different value by design, replace it by gh-ost para" />
      <item value="NextOffset returns the next offset that should be consumed for the managed partition, accompanied by metadata which can be used to reconstruct the state of the partition consumer when it resumes. NextOffset() will return `config.Consumer.Offsets.Initial` and an empty metadata string if no offset was committed for this partition yet." />
      <item value="MarkOffset marks the provided offset, alongside a metadata string that represents the state of the partition consumer at that point in time. The metadata string can be used by another consumer to restore that state, so it can resume consumption. To follow upstream conventions, you are expected to mark the offset of the next message to read, not the last message read. Thus, when calling `MarkOffset` you should typically add one to the offset of the last consumed message. Note: calling MarkOffset does not necessarily commit the offset to the backend store immediately for efficiency reasons, and it may never be committed if your application crashes. This means that you may end up processing the same message twice, and your processing should ideally be idempotent." />
      <item value="score" />
      <item value="Split slices s into all substrings separated by sep and returns a slice of the substrings between those separators. If s does not contain sep and sep is not empty, Split returns a slice of length 1 whose only element is s. If sep is empty, Split splits after each UTF-8 sequence. If both s and sep are empty, Split returns an empty slice. It is equivalent to [SplitN] with a count of -1. To split around the first instance of a separator, see [Cut]." />
      <item value="IsConfirm makes the prompt ask for a yes or no ([YN]) question rather than request an input. When set, most properties related to input will be ignored." />
      <item value="SCRAMClientGeneratorFunc is a generator of a user provided implementation of a SCRAM client used to perform the SCRAM exchange with the server." />
      <item value="SASL based authentication with broker. While there are multiple SASL authentication methods the current implementation is limited to plaintext (SASLPLAIN) authentication SASL struct { Whether or not to use SASL authentication when connecting to the broker (defaults to false). Enable bool SASLMechanism is the name of the enabled SASL mechanism. Possible values: OAUTHBEARER, PLAIN (defaults to PLAIN). Mechanism SASLMechanism Version is the SASL Protocol Version to use Kafka &gt; 1.x should use V1, except on Azure EventHub which use V0 Version int16 Whether or not to send the Kafka SASL handshake first if enabled (defaults to true). You should only set this to false if you're using a non-Kafka SASL proxy. Handshake bool AuthIdentity is an (optional) authorization identity (authzid) to use for SASLPLAIN authentication (if different from User) when an authenticated user is permitted to act as the presented alternative user. See RFC4616 for details. AuthIdentity string User is the authentication identity (authcid) to present for SASLPLAIN or SASLSCRAM authentication User string Password for SASLPLAIN authentication Password string authz id used for SASLSCRAM authentication SCRAMAuthzID string SCRAMClientGeneratorFunc is a generator of a user provided implementation of a SCRAM client used to perform the SCRAM exchange with the server. SCRAMClientGeneratorFunc func() SCRAMClient TokenProvider is a user-defined callback for generating access tokens for SASLOAUTHBEARER auth. See the AccessTokenProvider interface docs for proper implementation guidelines. TokenProvider AccessTokenProvider GSSAPI GSSAPIConfig }" />
      <item value="SASL based authentication with broker. While there are multiple SASL authentication methods the current implementation is limited to plaintext (SASLPLAIN) authentication" />
      <item value="ReleaseLock releases a distributed lock in Redis. It ensures that the lock is only released by the owner who acquired it." />
      <item value="set to 'true' when you know for certain your server uses 'ROW' binlog_format. gh-ost is unable to tell, event after reading binlog_format, whether the replication process does indeed use 'ROW', and restarts replication to be certain RBR setting is applied. Such operation requires SUPER privileges which you might not have. Setting this flag avoids restarting replication and you can proceed to use gh-ost without SUPER privileges" />
      <item value="let this tool automatically switch binary log format to 'ROW' on the replica, if needed. The format will NOT be switched back. I'm too scared to do that, and wish to protect you if you happen to execute another migration while this one is running" />
      <item value="ExecNoPrepare executes given query using given args on given DB, without using prepared statements." />
      <item value="restartReplication is required so that we are _certain_ the binlog format and row image settings have actually been applied to the replication thread. It is entirely possible, for example, that the replication is using 'STATEMENT' binlog format even as the variable says 'ROW'" />
      <item value="MaxConnsPerHost optionally limits the total number of connections per host, including connections in the dialing, active, and idle states. On limit violation, dials will block. Zero means no limit." />
      <item value="Timeout specifies a time limit for requests made by this Client. The timeout includes connection time, any redirects, and reading the response body. The timer remains running after Get, Head, Post, or Do return and will interrupt reading of the Response.Body. A Timeout of zero means no timeout. The Client cancels requests to the underlying Transport as if the Request's Context ended. For compatibility, the Client will also use the deprecated CancelRequest method on Transport if found. New RoundTripper implementations should use the Request's Context for cancellation instead of implementing CancelRequest." />
      <item value="The maximum permitted size of a message (defaults to 1000000). Should be set equal to or smaller than the broker's `message.max.bytes`." />
      <item value="app: name: udp_producer debug: true slow_log_threshold: 2000 ms connection: mysql: - name: udp host: dbm.office.udp.domob-inc.cn port: 3332 user: udp password: udp_rw@Domob21 database: udp charset: utf8mb4 max_open_conns: 100 max_idle_conns: 100 conn_max_lifetime: 60 conn_max_idle_time: 5 - name: udp_v2 host: dbm.office.udp.domob-inc.cn port: 3332 user: udp password: udp_rw@Domob21 database: udp_v2 charset: utf8mb4 max_open_conns: 300 max_idle_conns: 300 conn_max_lifetime: 60 conn_max_idle_time: 5 http: port: 19137 prometheus: enable: false port: 22017 logger: - scenario: system logger_info: - level: debug filename: systeminfo___POD__.log max_size: 200 MB max_age: 7 localtime: true - level: warn filename: systemwarn___POD__.log max_size: 200 max_age: 7 localtime: true - level: error filename: systemerror___POD__.log max_size: 200 max_age: 7 localtime: true stack_trace_key: stacktrace - scenario: notify logger_info: - level: debug filename: notifyinfo___POD__.log max_size: 200 MB max_age: 7 localtime: true - level: error filename: notifyerror___POD__.log max_size: 200 max_age: 7 localtime: true stack_trace_key: stacktrace - scenario: mysql logger_info: - level: debug filename: mysqlinfo___POD__.log max_size: 200 MB max_age: 7 localtime: true - level: warn filename: mysqlwarn___POD__.log max_size: 200 max_age: 7 localtime: true stack_trace_key: stacktrace - level: error filename: mysqlerror___POD__.log max_size: 200 max_age: 7 localtime: true stack_trace_key: stacktrace - scenario: http logger_info: - level: debug filename: httpinfo___POD__.log max_size: 200 MB max_age: 7 localtime: true - level: error filename: httperror___POD__.log max_size: 200 max_age: 7 localtime: true stack_trace_key: stacktrace - scenario: cron logger_info: - level: debug filename: croninfo___POD__.log max_size: 200 MB max_age: 7 localtime: true - level: error filename: cronerror___POD__.log max_size: 200 max_age: 7 localtime: true stack_trace_key: stacktrace - scenario: tencent_producer logger_info: - level: debug filename: producertencentinfo___POD__.log max_size: 200 MB max_age: 30 localtime: true - level: error filename: producertencenterror___POD__.log max_size: 200 max_age: 30 localtime: true stack_trace_key: stacktrace webhook: - scenario: notify 限制机器人在什么场景下发送消息 webhook_info: fs_dev: https:open.feishu.cnopen-apisbotv2hook3e1030d6-fed9-4c46-9b1b-782c7862ea37 - scenario: success webhook_info: fs_dev: https:open.feishu.cnopen-apisbotv2hook3e1030d6-fed9-4c46-9b1b-782c7862ea37 feishu: rate_limit: 1 限制每秒钟发送消息的数量 crontab: name 是待执行的方法名，必须是对外导出的方法，参考 internal.AddCron() spec 是 crontab 的规则，参考 https:godoc.orggithub.comrobfigcronhdr-CRON_Expression_Format - name: CreateTasksTableIfNotExist 定时创建第二天的任务表 open: true spec: &quot;0 4 &quot; producer: tencent: - name: GetAdvertisersByAgencyId 通过代理商拉取广告主元信息 open: false spec: &quot;48 17 &quot; queue: slow - name: GetAdvertiserFund 拉取代理商资金信息 open: false spec: &quot;48 17 &quot; queue: fast - name: GetAgencyFund 拉取全量广告主账户资金信息 open: false spec: &quot;48 17 &quot; queue: fast batch_size: 1000 批次大小，每批1000个 batch_dispatch_time: 120 分钟，2小时内跑完 - name: GetAdgroup 拉取有消耗的广告主账户下的广告组信息 open: false spec: &quot;11 18 &quot; queue: fast - name: GetDynamicCreative 拉取有消耗的广告主账户下的动态创意信息 open: false spec: &quot;54 13 &quot; queue: slow - name: GetAdDailyReportByAdvertiserIdAsync 拉取有消耗的广告主账户下的广告创意天级报表 open: false spec: &quot;24 18 &quot; queue: fast max_retry_cnt: 20 max_retry_interval: 300 min_retry_interval: 10 - name: GetAdDailyHisReportByAdvertiserIdAsync 拉取有消耗的广告主账户下的广告创意天级历史报表 open: false spec: &quot;24 18 &quot; queue: fast lookback_days: 2 回溯 2 天的数据 max_retry_cnt: 20 max_retry_interval: 300 min_retry_interval: 10 - name: GetAccountDailyReportByAgencyIdAsync 通过代理商拉取广告主账户天级实时报表 open: false spec: &quot;48 17 &quot; queue: fast max_retry_cnt: 20 max_retry_interval: 300 min_retry_interval: 10 - name: GetAccountDailyHisReportByAgencyIdAsync 通过代理商拉取广告主账户天级历史报表 open: false spec: &quot;48 17 &quot; queue: fast lookback_days: 2 回溯 2 天的数据 max_retry_cnt: 20 max_retry_interval: 300 min_retry_interval: 10 - name: GetAllAccountDailyReport 拉取全量广告主账户天级实时报表 open: false spec: &quot;08 20 &quot; queue: fast - name: GetAccountDailyReport 拉取有消耗的广告主账户天级实时报表 open: false spec: &quot;13 11 &quot; queue: fast - name: GetAccountDailyHisReport 拉取全量广告主账户天级历史报表 open: false spec: &quot;09 17 &quot; queue: fast lookback_days: 2 回溯 2 天的数据 - name: GetAccountHourlyReport 拉取有消耗的广告主账户小时实时报表 open: false spec: &quot;11 18 &quot; queue: fast - name: GetAccountHourlyHisReport 拉取有消耗的广告主账户小时历史报表 open: false spec: &quot;11 18 &quot; queue: fast lookback_days: 2 回溯 2 天的数据 - name: GetAdvertiserDailyBalanceReport 拉取全量广告主账户日结明细报表 open: false spec: &quot;09 17 &quot; queue: fast lookback_days: 2 回溯 2 天的数据 toutiao: - name: open: false spec: &quot;20 17 &quot; queue: fast" />
      <item value="Top-level convenience functions globalRand is the source of random numbers for the top-level convenience functions." />
      <item value="Read is a helper function that calls Reader.Read using io.ReadFull. On return, n == len(b) if and only if err == nil." />
      <item value="MEDIUMTEXT" />
      <item value="queries a single column from a model, returning in the slice dest. E.g.:" />
      <item value="wall and ext encode the wall time seconds, wall time nanoseconds, and optional monotonic clock reading in nanoseconds. From high to low bit position, wall encodes a 1-bit flag (hasMonotonic), a 33-bit seconds field, and a 30-bit wall time nanoseconds field. The nanoseconds field is in the range [0, 999999999]. If the hasMonotonic bit is 0, then the 33-bit field must be zero and the full signed 64-bit wall seconds since Jan 1 year 1 is stored in ext. If the hasMonotonic bit is 1, then the 33-bit field holds a 33-bit unsigned wall seconds since Jan 1 year 1885, and ext holds a signed 64-bit monotonic clock reading, nanoseconds since process start." />
      <item value="Unix returns the local Time corresponding to the given Unix time, sec seconds and nsec nanoseconds since January 1, 1970 UTC. It is valid to pass nsec outside the range [0, 999999999]. Not all sec values have a corresponding time value. One such value is 1&lt;&lt;63-1 (the largest int64 value)." />
      <item value="Acquire" />
      <item value="Read reads one record (a slice of fields) from r. If the record has an unexpected number of fields, Read returns the record along with the error [ErrFieldCount]. If the record contains a field that cannot be parsed, Read returns a partial record along with the parse error. The partial record contains all fields read before the error. If there is no data left to be read, Read returns nil, [io.EOF]. If [Reader.ReuseRecord] is true, the returned slice may be shared between multiple calls to Read." />
      <item value="SetOutputDirectory method sets the output directory for saving HTTP responses in a file. Resty creates one if the output directory does not exist. This setting is optional, if you plan to use the absolute path in [Request.SetOutput] and can used together. client.SetOutputDirectory(&quot;savehttpresponsehere&quot;)" />
      <item value="SetOutput method sets the output file for the current HTTP request. The current HTTP response will be saved in the given file. It is similar to the `curl -o` flag. Absolute path or relative path can be used. If it is a relative path, then the output file goes under the output directory, as mentioned in the [Client.SetOutputDirectory]. client.R(). SetOutput(&quot;UsersjeevaDownloadsReplyWithHeader-v5.1-beta.zip&quot;). Get(&quot;http:bit.ly1LouEKr&quot;) NOTE: In this scenario [Response.Body] might be nil." />
      <item value="PipeCursor is a pipe character &quot;|&quot; which appears before the input" />
      <item value="BlockCursor is a cursor which highlights a character by inverting colors" />
      <item value="DefaultCursor is a big square block character. Obscures whatever was" />
      <item value="the Pointer defines how to render the cursor." />
      <item value="IsVimMode enables vi-like movements (hjkl) and editing." />
      <item value="Templates can be used to customize the prompt output. If nil is passed, the default templates are used. See the PromptTemplates docs for more info." />
      <item value="HideEntered sets whether to hide the text after the user has pressed enter." />
      <item value="Mask is an optional rune that sets which character to display instead of the entered characters. This allows hiding private information like passwords." />
    </histories>
    <option name="languageScores">
      <map>
        <entry key="CHINESE" value="97" />
        <entry key="CHINESE_SIMPLIFIED" value="110" />
        <entry key="ENGLISH" value="208" />
      </map>
    </option>
  </component>
</application>